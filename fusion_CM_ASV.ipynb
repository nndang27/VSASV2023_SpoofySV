{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6be1420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:38.001277Z",
     "iopub.status.busy": "2023-10-26T15:45:38.000511Z",
     "iopub.status.idle": "2023-10-26T15:45:39.119067Z",
     "shell.execute_reply": "2023-10-26T15:45:39.117885Z"
    },
    "papermill": {
     "duration": 1.129321,
     "end_time": "2023-10-26T15:45:39.121477",
     "exception": false,
     "start_time": "2023-10-26T15:45:37.992156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/doubleroc/* /kaggle/working/SASV_DoubleRoc-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c409a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:39.135556Z",
     "iopub.status.busy": "2023-10-26T15:45:39.135197Z",
     "iopub.status.idle": "2023-10-26T15:45:40.091733Z",
     "shell.execute_reply": "2023-10-26T15:45:40.090572Z"
    },
    "papermill": {
     "duration": 0.96601,
     "end_time": "2023-10-26T15:45:40.093975",
     "exception": false,
     "start_time": "2023-10-26T15:45:39.127965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/nndang-fusion-test /kaggle/working/SASV_DoubleRoc-main/fusion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdf541e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:40.107577Z",
     "iopub.status.busy": "2023-10-26T15:45:40.107270Z",
     "iopub.status.idle": "2023-10-26T15:45:41.058664Z",
     "shell.execute_reply": "2023-10-26T15:45:41.057598Z"
    },
    "papermill": {
     "duration": 0.960829,
     "end_time": "2023-10-26T15:45:41.061004",
     "exception": false,
     "start_time": "2023-10-26T15:45:40.100175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/nndang-spoofing-data /kaggle/working/SASV_DoubleRoc-main/spoofing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd93785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:41.074522Z",
     "iopub.status.busy": "2023-10-26T15:45:41.074202Z",
     "iopub.status.idle": "2023-10-26T15:45:42.026019Z",
     "shell.execute_reply": "2023-10-26T15:45:42.024563Z"
    },
    "papermill": {
     "duration": 0.962157,
     "end_time": "2023-10-26T15:45:42.029445",
     "exception": false,
     "start_time": "2023-10-26T15:45:41.067288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/nndang-vn-celeb/VLSP23_VN_celeb2 /kaggle/working/SASV_DoubleRoc-main/vn-celeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00b9fe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:42.048225Z",
     "iopub.status.busy": "2023-10-26T15:45:42.047894Z",
     "iopub.status.idle": "2023-10-26T15:45:43.065684Z",
     "shell.execute_reply": "2023-10-26T15:45:43.064500Z"
    },
    "papermill": {
     "duration": 1.028871,
     "end_time": "2023-10-26T15:45:43.068002",
     "exception": false,
     "start_time": "2023-10-26T15:45:42.039131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/weight-cm /kaggle/working/SASV_DoubleRoc-main/CM_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54aa789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:43.082214Z",
     "iopub.status.busy": "2023-10-26T15:45:43.081913Z",
     "iopub.status.idle": "2023-10-26T15:45:44.067585Z",
     "shell.execute_reply": "2023-10-26T15:45:44.066297Z"
    },
    "papermill": {
     "duration": 0.995917,
     "end_time": "2023-10-26T15:45:44.070084",
     "exception": false,
     "start_time": "2023-10-26T15:45:43.074167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/tst-enr /kaggle/working/SASV_DoubleRoc-main/enrollment_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4da7deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:44.083952Z",
     "iopub.status.busy": "2023-10-26T15:45:44.083566Z",
     "iopub.status.idle": "2023-10-26T15:45:45.025411Z",
     "shell.execute_reply": "2023-10-26T15:45:45.024107Z"
    },
    "papermill": {
     "duration": 0.951705,
     "end_time": "2023-10-26T15:45:45.027980",
     "exception": false,
     "start_time": "2023-10-26T15:45:44.076275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/ecapa-tdnn /kaggle/working/SASV_DoubleRoc-main/ecapa-tdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab03972f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:45.042607Z",
     "iopub.status.busy": "2023-10-26T15:45:45.042270Z",
     "iopub.status.idle": "2023-10-26T15:45:46.000702Z",
     "shell.execute_reply": "2023-10-26T15:45:45.999630Z"
    },
    "papermill": {
     "duration": 0.969092,
     "end_time": "2023-10-26T15:45:46.003013",
     "exception": false,
     "start_time": "2023-10-26T15:45:45.033921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/vn-celeb-txt-final /kaggle/working/SASV_DoubleRoc-main/vn_celeb_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648217af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:46.017177Z",
     "iopub.status.busy": "2023-10-26T15:45:46.016803Z",
     "iopub.status.idle": "2023-10-26T15:45:46.959754Z",
     "shell.execute_reply": "2023-10-26T15:45:46.958544Z"
    },
    "papermill": {
     "duration": 0.952925,
     "end_time": "2023-10-26T15:45:46.962115",
     "exception": false,
     "start_time": "2023-10-26T15:45:46.009190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/emb-roc /kaggle/working/SASV_DoubleRoc-main/emb_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155e35db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:46.975698Z",
     "iopub.status.busy": "2023-10-26T15:45:46.975302Z",
     "iopub.status.idle": "2023-10-26T15:45:47.924503Z",
     "shell.execute_reply": "2023-10-26T15:45:47.923297Z"
    },
    "papermill": {
     "duration": 0.958701,
     "end_time": "2023-10-26T15:45:47.927001",
     "exception": false,
     "start_time": "2023-10-26T15:45:46.968300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/public-tst /kaggle/working/SASV_DoubleRoc-main/public_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3828d65b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:47.940610Z",
     "iopub.status.busy": "2023-10-26T15:45:47.940247Z",
     "iopub.status.idle": "2023-10-26T15:45:48.888887Z",
     "shell.execute_reply": "2023-10-26T15:45:48.887569Z"
    },
    "papermill": {
     "duration": 0.958488,
     "end_time": "2023-10-26T15:45:48.891439",
     "exception": false,
     "start_time": "2023-10-26T15:45:47.932951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/ecapa-weight /kaggle/working/SASV_DoubleRoc-main/weight_ecapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52aa6912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:48.905159Z",
     "iopub.status.busy": "2023-10-26T15:45:48.904850Z",
     "iopub.status.idle": "2023-10-26T15:45:49.847524Z",
     "shell.execute_reply": "2023-10-26T15:45:49.846422Z"
    },
    "papermill": {
     "duration": 0.952135,
     "end_time": "2023-10-26T15:45:49.850013",
     "exception": false,
     "start_time": "2023-10-26T15:45:48.897878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/cm-weight-new /kaggle/working/SASV_DoubleRoc-main/cm_weight_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b34df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:49.864364Z",
     "iopub.status.busy": "2023-10-26T15:45:49.863558Z",
     "iopub.status.idle": "2023-10-26T15:45:50.814255Z",
     "shell.execute_reply": "2023-10-26T15:45:50.813102Z"
    },
    "papermill": {
     "duration": 0.960793,
     "end_time": "2023-10-26T15:45:50.816900",
     "exception": false,
     "start_time": "2023-10-26T15:45:49.856107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/pkl-s2pecnet-data /kaggle/working/SASV_DoubleRoc-main/pkl-s2pecnet-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae737c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:50.830459Z",
     "iopub.status.busy": "2023-10-26T15:45:50.830149Z",
     "iopub.status.idle": "2023-10-26T15:45:51.778764Z",
     "shell.execute_reply": "2023-10-26T15:45:51.777681Z"
    },
    "papermill": {
     "duration": 0.958254,
     "end_time": "2023-10-26T15:45:51.781122",
     "exception": false,
     "start_time": "2023-10-26T15:45:50.822868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s /kaggle/input/public-tst-pkl /kaggle/working/SASV_DoubleRoc-main/pubilc_tst_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "371e7ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:51.795237Z",
     "iopub.status.busy": "2023-10-26T15:45:51.794700Z",
     "iopub.status.idle": "2023-10-26T15:45:51.805031Z",
     "shell.execute_reply": "2023-10-26T15:45:51.804113Z"
    },
    "papermill": {
     "duration": 0.01993,
     "end_time": "2023-10-26T15:45:51.807233",
     "exception": false,
     "start_time": "2023-10-26T15:45:51.787303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/SASV_DoubleRoc-main/ASV/save_embeddings.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/SASV_DoubleRoc-main/ASV/save_embeddings.py\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import torch.nn as nn\n",
    "from typing import Dict, List\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from test_dataset import get_dataloader\n",
    "from models.ResNet34V2 import MainModel as ResNet34V2\n",
    "from models.ECAPATDNN import MainModel as ECAPATDNN\n",
    "from models.Res2Net50V2 import MainModel as Res2Net50V2\n",
    "from models.Res2NeXt50 import MainModel as Res2NeXt50\n",
    "from models.WavLMLarge import MainModel as WavLMLarge\n",
    "\n",
    "vn_celeb_trn_path = \"/kaggle/working/SASV_DoubleRoc-main/vn_celeb_txt/train_list_final.txt\"\n",
    "vn_celeb_tst_path = \"/kaggle/working/SASV_DoubleRoc-main/public_tst/example_submission/submission.txt\"\n",
    "cm_tst_bf = \"/kaggle/working/SASV_DoubleRoc-main/public_tst/example_submission/submission.txt\"\n",
    " \n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--LA_dataset_path', type=str, default='LA', help='The model to Run')\n",
    "    parser.add_argument(\n",
    "        \"--ASV_embedings_save_path\", type=str, default=\"embeddings\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\", type=str, default=\"ECAPATDNN\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpu\", type=str, default=\"0\"\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device: {}\".format(device))\n",
    "    LA_dataset_path = args.LA_dataset_path\n",
    "    if not os.path.exists(LA_dataset_path):\n",
    "        print('LA Datset is not exist.')\n",
    "        exit(0)\n",
    "    if args.model == 'ECAPATDNN':\n",
    "        model = ECAPATDNN('/kaggle/working/SASV_DoubleRoc-main/weight_ecapa/model_0070.model')\n",
    "    elif args.model == 'ResNet34V2':\n",
    "        model = ResNet34V2('./weights/resnet34v2.model')\n",
    "    elif args.model == 'Res2Net50V2':\n",
    "        model = Res2Net50V2('./weights/res2net50v2.model')\n",
    "    elif args.model == 'Res2NeXt50':\n",
    "        model = Res2NeXt50('./weights/res2next50.model')\n",
    "    elif args.model == 'WavLMLarge':\n",
    "        model = WavLMLarge('./weights/wavlm_large_finetune.model')\n",
    "    else:\n",
    "        print(f'model {args.model} is not supoort.')\n",
    "        exit(0)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "    #for data_dirname in ['train_celeb', 'valid_celeb', 'enr_set']:\n",
    "    #if data_dirname == \"train_celeb\":\n",
    "    #    meta_lines = open(vn_celeb_trn_path, \"r\").readlines()\n",
    "    #if data_dirname == \"valid_celeb\":\n",
    "    meta_lines = open(vn_celeb_tst_path, \"r\").readlines()\n",
    "    #elif data_dirname == \"enr_set\":\n",
    "    utt_enr_list = []\n",
    "    utt_tst_list = []\n",
    "    for line in meta_lines:\n",
    "        tmp = line.strip().split('\\t')\n",
    "        spk = tmp[0]\n",
    "        utt = tmp[1]\n",
    "        if utt not in utt_tst_list:\n",
    "            utt_tst_list.append(utt)\n",
    "        if spk not in utt_enr_list:\n",
    "            utt_enr_list.append(spk)\n",
    "    path = \"/kaggle/working/SASV_DoubleRoc-main/public_tst/\"\n",
    "    sasv_tst = get_dataloader(path, utt_tst_list)\n",
    "    sasv_enr = get_dataloader(path, utt_enr_list)\n",
    "    #for sasv_dataloader in [\"sasv_tst\", \"sasv_enr\"]:\n",
    "    spk_emb_dic = {}\n",
    "    with torch.no_grad():\n",
    "        for idx, (data_1s, data_2s, files) in  tqdm.tqdm(enumerate(sasv_tst), total = len(sasv_tst)):\n",
    "            data_1 = data_1s[0].cuda()\n",
    "            data_2 = data_2s[0].cuda()\n",
    "            file = files[0]\n",
    "\n",
    "            embedding_1 = model(data_1)\n",
    "            embedding_1_norm = F.normalize(embedding_1, p=2, dim=1)\n",
    "            embedding_2 = model(data_2)\n",
    "            embedding_2_norm  = F.normalize(embedding_2, p=2, dim=1)\n",
    "            embedding = torch.cat([embedding_1, embedding_2], dim=0).detach().cpu().numpy()\n",
    "            embedding_norm = torch.cat([embedding_1_norm, embedding_2_norm], dim=0).detach().cpu().numpy()\n",
    "            spk_emb_dic[file] = embedding_norm\n",
    "            #spk_emb_norm_dic[file] = embedding_norm\n",
    "    os.makedirs(os.path.join(args.ASV_embedings_save_path, args.model), exist_ok=True)\n",
    "    with open( f\"{os.path.join(args.ASV_embedings_save_path, args.model)}/sasv_tst.pk\", \"wb\") as f:\n",
    "        pk.dump(spk_emb_dic, f)\n",
    "        \n",
    "    spk_emb_dic = {}\n",
    "    with torch.no_grad():\n",
    "        for idx, (data_1s, data_2s, files) in  tqdm.tqdm(enumerate(sasv_enr), total = len(sasv_enr)):\n",
    "            data_1 = data_1s[0].cuda()\n",
    "            data_2 = data_2s[0].cuda()\n",
    "            file = files[0]\n",
    "\n",
    "            embedding_1 = model(data_1)\n",
    "            embedding_1_norm = F.normalize(embedding_1, p=2, dim=1)\n",
    "            embedding_2 = model(data_2)\n",
    "            embedding_2_norm  = F.normalize(embedding_2, p=2, dim=1)\n",
    "            embedding = torch.cat([embedding_1, embedding_2], dim=0).detach().cpu().numpy()\n",
    "            embedding_norm = torch.cat([embedding_1_norm, embedding_2_norm], dim=0).detach().cpu().numpy()\n",
    "            spk_emb_dic[file] = embedding_norm\n",
    "            #spk_emb_norm_dic[file] = embedding_norm   \n",
    "    with open( f\"{os.path.join(args.ASV_embedings_save_path, args.model)}/sasv_enr.pk\", \"wb\") as f:\n",
    "        pk.dump(spk_emb_dic, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3bac8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:51.821005Z",
     "iopub.status.busy": "2023-10-26T15:45:51.820710Z",
     "iopub.status.idle": "2023-10-26T15:45:51.827414Z",
     "shell.execute_reply": "2023-10-26T15:45:51.826564Z"
    },
    "papermill": {
     "duration": 0.016111,
     "end_time": "2023-10-26T15:45:51.829410",
     "exception": false,
     "start_time": "2023-10-26T15:45:51.813299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/SASV_DoubleRoc-main/ASV/test_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/SASV_DoubleRoc-main/ASV/test_dataset.py\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import soundfile as sf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\n",
    "\n",
    "def transform_string(dong):\n",
    "    # Sử dụng biểu thức chính quy để tìm các phần tử id trong dòng\n",
    "    match = re.match(r'BF_id(\\d{5})_(\\d{8})', dong)\n",
    "    \n",
    "    if match:\n",
    "        # Lấy các phần tử id từ kết quả tìm được\n",
    "        id1, id2 = match.groups()\n",
    "        # Chuyển đổi sang định dạng mong muốn\n",
    "        ket_qua = f'id{id1.zfill(5)}/{id2.zfill(8)}'\n",
    "        return ket_qua\n",
    "    else:\n",
    "        # Trả về dòng ban đầu nếu không tìm thấy kết quả phù hợp\n",
    "        return dong\n",
    "\n",
    "\n",
    "class SASVTestDataset(Dataset):\n",
    "    def __init__(self, eval_path, list_id, num_frames=300):\n",
    "        super().__init__()\n",
    "        self.eval_path = eval_path\n",
    "        self.list_id = list_id\n",
    "        self.num_frames = num_frames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_id)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return super().__getitem__(index)\n",
    "        file = self.list_id[index]\n",
    "        audio_path = self.eval_path + f\"{file}\"\n",
    "        audio, _  = sf.read(audio_path)\n",
    "        # Full utterance 完整的一句\n",
    "        data_1 = torch.FloatTensor(np.stack([audio],axis=0))\n",
    "\n",
    "        # Spliited utterance matrix 将语音切片\n",
    "        max_audio = self.num_frames * 160 + 240\n",
    "        if audio.shape[0] <= max_audio:\n",
    "            shortage = max_audio - audio.shape[0]\n",
    "            audio = np.pad(audio, (0, shortage), 'wrap')\n",
    "        feats = []\n",
    "        startframe = np.linspace(0, audio.shape[0]-max_audio, num=5)\n",
    "        for asf in startframe:\n",
    "            feats.append(audio[int(asf):int(asf)+max_audio])\n",
    "        feats = np.stack(feats, axis = 0).astype(np.float)\n",
    "        data_2 = torch.FloatTensor(feats)\n",
    "        return data_1, data_2, file\n",
    "\n",
    "def get_dataloader(eval_path, list_id):\n",
    "    sasv_dataset = SASVTestDataset(eval_path, list_id)\n",
    "    sasv_dataloader = DataLoader(dataset=sasv_dataset, batch_size=1, num_workers=4)\n",
    "    return sasv_dataloader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c70bdb10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:45:51.842535Z",
     "iopub.status.busy": "2023-10-26T15:45:51.842235Z",
     "iopub.status.idle": "2023-10-26T15:51:40.704612Z",
     "shell.execute_reply": "2023-10-26T15:51:40.703535Z"
    },
    "papermill": {
     "duration": 348.871778,
     "end_time": "2023-10-26T15:51:40.707062",
     "exception": false,
     "start_time": "2023-10-26T15:45:51.835284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\r\n",
      "spk model load model_0070.model\r\n",
      "100%|███████████████████████████████████████| 4766/4766 [02:00<00:00, 39.57it/s]\r\n",
      "100%|███████████████████████████████████████| 9063/9063 [03:21<00:00, 44.93it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/SASV_DoubleRoc-main/ASV/save_embeddings.py --model ECAPATDNN --LA_dataset_path \"/kaggle/working/SASV_DoubleRoc-main/public_tst/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970af1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:51:41.141782Z",
     "iopub.status.busy": "2023-10-26T15:51:41.141406Z",
     "iopub.status.idle": "2023-10-26T15:51:41.154150Z",
     "shell.execute_reply": "2023-10-26T15:51:41.153260Z"
    },
    "papermill": {
     "duration": 0.232058,
     "end_time": "2023-10-26T15:51:41.156148",
     "exception": false,
     "start_time": "2023-10-26T15:51:40.924090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/SASV_DoubleRoc-main/ASV/test_asv_cm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/SASV_DoubleRoc-main/ASV/test_asv_cm.py\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import soundfile as sf\n",
    "from torch import Tensor\n",
    "import torch, time, sys, tqdm\n",
    "from utils import get_all_EERs\n",
    "from models.AASIST import MainModel as CMModel\n",
    "from models.S2pecNet import MainModel as S2pecNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--LA_dataset_path', type=str, default='/kaggle/working/SASV_DoubleRoc-main/public_tst/', help='The model to Run')\n",
    "    parser.add_argument(\n",
    "        \"--ASV_embedings_save_path\", type=str, default=\"/kaggle/working/embeddings/ECAPATDNN/\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\", type=str, default=\"ECAPATDNN\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--norm\", type=str, default=\"l2norm\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpu\", type=str, default=\"0\"\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "def init_cm_model(cm_weight_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    cm_model = CMModel(cm_weight_path)\n",
    "    cm_model = cm_model.to(device)\n",
    "    cm_model = cm_model.eval()\n",
    "    for module in cm_model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "    return cm_model\n",
    "\n",
    "def init_cm_model_1(cm_weight_path):\n",
    "    device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
    "    cm_model = S2pecNet(cm_weight_path)\n",
    "    cm_model = cm_model.to(device)\n",
    "    cm_model = cm_model.eval()\n",
    "    for module in cm_model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.track_running_stats = False\n",
    "            module.eval()\n",
    "    return cm_model\n",
    "\n",
    "def transform_string(input_string):\n",
    "    # Tách lấy phần cuối của đường dẫn (tức là tên tệp tin)\n",
    "    file_name = os.path.basename(input_string)\n",
    "    \n",
    "    # Loại bỏ phần mở rộng '.wav' và thay thế bằng 'LFCC.pkl'\n",
    "    transformed_name = file_name.replace('.wav', 'LFCC.pkl')\n",
    "    \n",
    "    return transformed_name\n",
    "\n",
    "def repeat_padding(spec, ref_len):\n",
    "    mul = int(np.ceil(ref_len / spec.shape[1]))\n",
    "    spec = spec.repeat(1, mul)[:, :ref_len]\n",
    "    return spec\n",
    "\n",
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\n",
    "\n",
    "class Dataset_devNeval(Dataset):\n",
    "    def __init__(self, base_dir, items, enr_emb, asv_embd, pkl_list, pkl_dir):\n",
    "        self.base_dir = base_dir\n",
    "        self.items = items\n",
    "        self.cut = 64600  # take ~4 sec audio (64600 samples), 这个对于CM系统可能需要修改\n",
    "        self.asv_embd = asv_embd\n",
    "        self.enr_emb = enr_emb\n",
    "        self.pkl_list = pkl_list\n",
    "        self.pkl_dir = pkl_dir\n",
    "        for key in asv_embd:\n",
    "            asv_embd[key] = asv_embd[key].mean(0)\n",
    "        for key in enr_emb:\n",
    "            enr_emb[key] = enr_emb[key].mean(0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        spk, tst = self.items[index]\n",
    "        X, _ = sf.read('{}{}'.format(self.base_dir, tst))\n",
    "        pkl_id = transform_string(tst)\n",
    "        with open(self.pkl_list[pkl_id], 'rb') as f:\n",
    "            lfcc = pickle.load(f)\n",
    "        lfcc = torch.from_numpy(lfcc)\n",
    "        this_feat_len = lfcc.shape[1]\n",
    "        if this_feat_len > 750:\n",
    "            lfcc = lfcc[:, :750]\n",
    "            \n",
    "        if this_feat_len < 750:\n",
    "            lfcc = repeat_padding(lfcc, 750)\n",
    "        lfcc = lfcc.float()\n",
    "        X_pad = pad(X, self.cut)\n",
    "        x_inp = Tensor(X_pad)\n",
    "        return self.enr_emb[spk], self.asv_embd[tst], x_inp, lfcc, index\n",
    "\n",
    "def gen_dev_and_eval_item_list(meta_path):\n",
    "    items = []\n",
    "    with open(meta_path, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            tmp = line.strip().split('\\t')\n",
    "            enr = tmp[0]\n",
    "            tst = tmp[1]\n",
    "            items.append([enr, tst])\n",
    "    return items\n",
    "\n",
    "\n",
    "def gen_loader(database_path, embedding_path, batch_size, n_cpu, norm):\n",
    "\n",
    "    dev_database_path  = database_path + \"/ASVspoof2019_LA_dev/\"\n",
    "    eval_database_path = \"/kaggle/working/SASV_DoubleRoc-main/public_tst/\"\n",
    "\n",
    "    dev_trial_path  = database_path + \"/ASVspoof2019_LA_asv_protocols/ASVspoof2019.LA.asv.dev.gi.trl.txt\"\n",
    "    eval_trial_path = \"/kaggle/working/SASV_DoubleRoc-main/public_tst/example_submission/submission.txt\"\n",
    "    eval_pk_path = \"/kaggle/working/SASV_DoubleRoc-main/pubilc_tst_pkl/PKL_public_test/eval/\"\n",
    "    # dev dataset setting\n",
    "    # dev_spk2ids, dev_items = gen_dev_and_eval_item_list([database_path + '/ASVspoof2019_LA_asv_protocols/ASVspoof2019.LA.asv.dev.male.trn.txt',\n",
    "    #                                                      database_path + '/ASVspoof2019_LA_asv_protocols/ASVspoof2019.LA.asv.dev.female.trn.txt'],\n",
    "    #                                                     dev_trial_path)\n",
    "    # dev_asv_embd = pickle.load(open(os.path.join(embedding_path, f'ASVspoof2019_LA_dev_{norm}.pk'), 'rb'))\n",
    "\n",
    "    # dev_dataset = Dataset_devNeval(base_dir=dev_database_path, spk2ids=dev_spk2ids, items=dev_items, asv_embd=dev_asv_embd)\n",
    "    # dev_loader = DataLoader(dataset=dev_dataset,\n",
    "    #                         batch_size=batch_size,\n",
    "    #                         shuffle=False,\n",
    "    #                         drop_last=False,\n",
    "    #                         pin_memory=True,\n",
    "    #                         num_workers=n_cpu)\n",
    "    # eval dataset setting\n",
    "    eval_items = gen_dev_and_eval_item_list(eval_trial_path)\n",
    "    eval_asv_embd = pickle.load(open(\"/kaggle/working/embeddings/ECAPATDNN/sasv_tst.pk\",'rb'))\n",
    "    enr_emb = pickle.load(open(\"/kaggle/working/embeddings/ECAPATDNN/sasv_enr.pk\",'rb'))\n",
    "    \n",
    "    public_tst_pkl_list = {}\n",
    "    files = os.listdir(eval_pk_path)\n",
    "    for file in files:\n",
    "        if os.path.isfile(os.path.join(eval_pk_path, file)):\n",
    "            public_tst_pkl_list[file] = os.path.join(eval_pk_path, file)\n",
    "        \n",
    "    eval_dataset = Dataset_devNeval(base_dir=eval_database_path, items=eval_items, enr_emb = enr_emb, asv_embd=eval_asv_embd, pkl_list = public_tst_pkl_list, pkl_dir = eval_pk_path)\n",
    "    eval_loader = DataLoader(dataset=eval_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=n_cpu)\n",
    "    return eval_loader\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device: {}\".format(device))\n",
    "    print(f'Model: {args.model}')\n",
    "    print(f'Norm: {args.norm}')\n",
    "    assert args.norm in ['l2norm', 'nonorm']\n",
    "    LA_dataset_path = args.LA_dataset_path\n",
    "    ASV_embedings_save_path = args.ASV_embedings_save_path\n",
    "    cm_model = init_cm_model_1('/kaggle/working/SASV_DoubleRoc-main/cm_weight_new/epoch_15_0.134.pth')\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6).to(device)\n",
    "    eval_loader = gen_loader(LA_dataset_path, os.path.join(ASV_embedings_save_path, args.model), batch_size=64, n_cpu=4, norm=args.norm)\n",
    "    tag_2_loader = {'eval': eval_loader}\n",
    "    for tag in tag_2_loader.keys():\n",
    "        loader = tag_2_loader[tag]\n",
    "        id2score = {}\n",
    "        id2label = {}\n",
    "        scores_list, labels_list = [], []\n",
    "        score_list_1 = []\n",
    "        for idx, (asv_embd_enr, asv_embd_tst, fusion_cm_data, lfcc, index) in enumerate(loader):\n",
    "            with torch.no_grad():\n",
    "                output = cm_model.forward(fusion_cm_data.to(device), lfcc.to(device))[1]\n",
    "                score1 =  output.softmax(-1).detach().cpu().numpy()[:, 1]\n",
    "                #score_1_list.append(score1)\n",
    "                score2 = cos(asv_embd_enr.to(device), asv_embd_tst.to(device)).detach().cpu().numpy()\n",
    "                score2 = (score2 + 1) / 2 #rút về khoảng [0,1]\n",
    "                score = score1 * score2\n",
    "                score_1 = score2 - score1\n",
    "                score_1 = abs(score_1.mean())\n",
    "                score_list_1.append(score_1)\n",
    "                index = index.detach().cpu().numpy()\n",
    "\n",
    "                for i, s in zip(index, score):\n",
    "                    #id2label[i] = l\n",
    "                    id2score[i] = s\n",
    "        for i in range(len(id2score.keys())):\n",
    "            scores_list.append(id2score[i])\n",
    "            #labels_list.append(id2label[i])\n",
    "        #sasv_EER, sv_EER, spf_EER = get_all_EERs(preds=scores_list, keys=labels_list)\n",
    "        #print(\"%s_sasvEER %2.2f%%, eval_svEER %2.2f%%, eval_spfEER %2.2f%%\" % (tag, sasv_EER * 100, sv_EER * 100, spf_EER * 100))\n",
    "with open(\"/kaggle/working/SASV_DoubleRoc-main/public_tst_result_mul.txt\", 'w') as f:\n",
    "    for item in scores_list:\n",
    "        f.write(\"%s\\n\" %item)\n",
    "\n",
    "with open(\"/kaggle/working/SASV_DoubleRoc-main/public_tst_result_plus.txt\", 'w') as f:\n",
    "    for item in score_list_1:\n",
    "        f.write(\"%s\\n\" %item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4b6cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:51:41.592990Z",
     "iopub.status.busy": "2023-10-26T15:51:41.592149Z",
     "iopub.status.idle": "2023-10-26T16:30:07.980467Z",
     "shell.execute_reply": "2023-10-26T16:30:07.979516Z"
    },
    "papermill": {
     "duration": 2306.609944,
     "end_time": "2023-10-26T16:30:07.983078",
     "exception": false,
     "start_time": "2023-10-26T15:51:41.373134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Device: cuda\r\n",
      "Model: ECAPATDNN\r\n",
      "Norm: l2norm\r\n",
      "cm model load epoch_15_0.134.pth\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/SASV_DoubleRoc-main/ASV/test_asv_cm.py --norm l2norm --model ECAPATDNN "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2673.780819,
   "end_time": "2023-10-26T16:30:08.421646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-26T15:45:34.640827",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
